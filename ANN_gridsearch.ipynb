{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-137a2edf-4b43-42c6-8f57-f4120ddb0f5a",
    "deepnote_cell_type": "code"
   },
   "source": "#Hyperparameter-Grid\n\n    num_layers=[1,2,3,4]\n    f_layer = 32\n\n    seed=[1,2,3,4,5]\n\n    batch_size = [32, 64, 96, 128,160,192,224,256]\n    batch_size_str = [\"batch 32\", \"batch 64\", \"batch 96\", \"batch 128\", \"batch 160\", \"batch 192\", \"batch 224\", \"batch 256\"]\n    kernel_initializer=['he_normal']\n\n    activation= [my_leaky_relu]\n    activation_str = ['leaky_relu']\n    \n    \n    \n    for s in seed:\n        np.random.seed(s)\n        tf.random.set_seed(s)\n        for act, act_str, kernel in zip(activation, activation_str, kernel_initializer):\n            for dim in num_layers:\n                for batch, batch_str in zip(batch_size, batch_size_str):\n\n                    time_start = time.perf_counter()\n\n                    #Layer Setup\n\n                    FFN = Sequential()\n\n                    for i in range(dim):\n                        FFN.add(Dense(int(f_layer / 2 ** i), kernel_initializer=kernel, input_dim=x_train_dim,\n                                      activation=act, kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n                        FFN.add(Dropout(0.1))\n                    FFN.add(Dense(1, kernel_initializer='normal', activation='linear'))\n                    FFN.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'])\n\n\n                    history = FFN.fit(x_train, y_train,\n                                      epochs=1000,\n                                      batch_size=batch,\n                                      shuffle=False,\n                                      validation_data=(x_val, y_val),\n                                      callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=10,\n                                                                                  restore_best_weights=True)])\n\n\n                                                                                   # Save the Model\n                    # FFN.save(data_dirAN +\"FFN\\\\Models\\\\\"  + \"FFN_\" +train+ dim_str + batch_str + \".h5\")\n\n\n\n\n                    # Visualization\n                    plt.plot(history.history['loss'], label='MSE (training data)')\n                    plt.plot(history.history['val_loss'], label='MSE (validation data)')\n                    # plt.title('MSE FFN' + dim_str + \"_\" + batch_str)\n                    plt.ylabel('MSE value')\n                    plt.xlabel('No. epoch')\n                    plt.legend(loc=\"best\")\n\n                    # Get the errors\n                    train_ev = FFN.evaluate(x_train, y_train, batch_size=batch)\n                    val_ev = FFN.evaluate(x_val, y_val, batch_size=batch)\n\n                    # Prediction\n                    y_hat_train = FFN.predict(x_train)\n                    y_hat_train = np.asarray(y_hat_train)\n\n                    y_hat_val = FFN.predict(x_val)\n                    y_hat_val = np.asarray(y_hat_val)\n\n                    y_hat_test = FFN.predict(x_test)\n                    y_hat_test = np.asarray(y_hat_test)\n\n                    # Computational time\n                    time_elapsed = (time.perf_counter() - time_start)\n                    print(time_elapsed)\n\n                    # Performance Evaluation\n                    R2_train = metrics.r2_score(y_train, y_hat_train)\n                    R2_val = metrics.r2_score(y_val, y_hat_val)\n                    R2_test = metrics.r2_score(y_test, y_hat_test)\n                    # Gu et al.'s non demeaned R2 (~Time Series R2)\n                    train_error = np.sum(np.square(y_train - y_hat_train))\n                    val_error = np.sum(np.square(y_val - y_hat_val))\n                    test_error = np.sum(np.square(y_test - y_hat_test))\n\n                    R2_gu_train = 1 - ((train_error) / (np.sum(np.square(y_train))))\n                    R2_gu_val = 1 - ((val_error) / (np.sum(np.square(y_val))))\n                    R2_gu_test = 1 - ((test_error) / (np.sum(np.square(y_test))))\n\n                    print(R2_gu_test)\n\n                    # Evaluation tabele\n                    string = train\n                    # string = train + dim_str + batch_str+'_'+act_str\n                    Liste = pd.Series(\n                        [string, train_ev, val_ev, time_elapsed, dim, batch, R2_train, R2_val, R2_test, R2_gu_train,\n                         R2_gu_val, R2_gu_test, act, s],\n                        index=[\"Network\", \"X-Train_MSE\", \"X-Val_MSE\", \"Computational_time\", \"Dimension\", \"Batch\",\n                               'R2_train', 'R2_val', 'R2_test', 'R2_gu_train', 'R2_gu_val', 'R2_gu_test', 'activation',\n                               'seed'])\n                    Evaluation_table_FFN = Evaluation_table_FFN.append(Liste, ignore_index=True)\n                    # plt.savefig(data_dirAN +\"FFN\\\\Plots\\\\\" +\"FFN_MSE\" + dim_str + batch_str +\"_\"+ train + \".png\")\n                    Evaluation_table_FFN.to_csv(data_dirAN + \"FFN\\\\\" + \"Evaluation_table_FFN\" + \".csv\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d30aab93-185d-4715-858f-78b8c83c5d5d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "131e58ac-b681-46b3-b7cc-968b66025945",
  "deepnote_execution_queue": []
 }
}